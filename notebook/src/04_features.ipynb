{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Feature Engineering - DDI Risk Analysis\n",
    "This notebook creates features for patient-level DDI risk analysis and clustering.\n",
    "\n",
    "**Approach:** Dual feature sets  \n",
    "- **Patient-level features**: For clustering and risk scoring  \n",
    "- **DDI pair-level features**: For detailed interaction analysis\n",
    "\n",
    "**Input**:  \n",
    "- `med-data/v2_clean/ddi/db_drug_interactions_clean.parquet`  \n",
    "- `med-data/v2_clean/medications/medications_clean.parquet`\n",
    "\n",
    "**Output**:  \n",
    "- `med-data/v3_features/patients_features.parquet` (one row per patient)  \n",
    "- `med-data/v3_features/ddi_pairs_features.parquet` (one row per patient DDI pair)\n",
    "\n",
    "**Future Enhancement**: After adding PhysioNet MIMIC-IV data, analyze care coordination  \n",
    "risks between VA and non-VA settings (fragmented care DDI analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow as pa\n",
    "from scipy.stats import entropy\n",
    "from importlib.metadata import version\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "version-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dependencies\n",
    "\n",
    "def print_version():\n",
    "    print(\"pandas:\", pd.__version__)\n",
    "    print(\"numpy:\", np.__version__)\n",
    "    print(\"scipy:\", version(\"scipy\"))\n",
    "    print(\"s3fs:\", s3fs.__version__)\n",
    "    print(\"pyarrow:\", pa.__version__)\n",
    "\n",
    "print_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logging-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logging configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "\n",
    "logging.info(f\"MinIO endpoint: {MINIO_ENDPOINT}\")\n",
    "logging.info(f\"Source: {DEST_BUCKET}/v2_clean/\")\n",
    "logging.info(f\"Destination: {DEST_BUCKET}/v3_features/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3fs-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3FileSystem for MinIO\n",
    "\n",
    "logging.info(f\"Initializing S3FileSystem for MinIO at {MINIO_ENDPOINT}\")\n",
    "fs = s3fs.S3FileSystem(\n",
    "    anon=False,\n",
    "    key=MINIO_ACCESS_KEY,\n",
    "    secret=MINIO_SECRET_KEY,\n",
    "    client_kwargs={'endpoint_url': f\"http://{MINIO_ENDPOINT}\"}\n",
    ")\n",
    "logging.info(\"S3FileSystem created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ddi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DDI clean dataset from v2_clean\n",
    "\n",
    "ddi_uri = f\"s3://{DEST_BUCKET}/{V2_CLEAN_DDI_PREFIX}db_drug_interactions_clean.parquet\"\n",
    "logging.info(f\"Reading DDI clean data: {ddi_uri}\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_ddi = pd.read_parquet(ddi_uri, filesystem=fs)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "logging.info(f\"Loaded {len(df_ddi):,} DDI records in {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"DDI Data Shape: {df_ddi.shape}\")\n",
    "print(f\"Columns: {list(df_ddi.columns)}\")\n",
    "df_ddi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-medications",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load medications clean dataset from v2_clean\n",
    "\n",
    "meds_uri = f\"s3://{DEST_BUCKET}/{V2_CLEAN_MEDICATIONS_PREFIX}medications_clean.parquet\"\n",
    "logging.info(f\"Reading medications clean data: {meds_uri}\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_meds = pd.read_parquet(meds_uri, filesystem=fs)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "logging.info(f\"Loaded {len(df_meds):,} medication records in {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\nMedications Data Shape: {df_meds.shape}\")\n",
    "print(f\"Columns: {list(df_meds.columns)}\")\n",
    "df_meds.head(3)\n",
    "\n",
    "# Load demographics clean dataset from v2_clean\n",
    "\n",
    "demo_uri = f\"s3://{DEST_BUCKET}/v2_clean/demographics/patient_demographics_clean.parquet\"\n",
    "logging.info(f\"Reading demographics clean data: {demo_uri}\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_demo = pd.read_parquet(demo_uri, filesystem=fs)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "logging.info(f\"Loaded {len(df_demo):,} patient demographics in {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\nDemographics Data Shape: {df_demo.shape}\")\n",
    "print(f\"Columns: {list(df_demo.columns)}\")\n",
    "df_demo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Patient-Level Features\n",
    "\n",
    "Create aggregated features for each patient to support clustering and risk scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-medication-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate medication profile features per patient\n",
    "\n",
    "logging.info(\"Calculating patient medication profile features...\")\n",
    "\n",
    "# Group by patient\n",
    "patient_features = df_meds.groupby('PatientSID').agg(\n",
    "    medication_count=('DrugName_Normalized', 'count'),\n",
    "    unique_medications=('DrugName_Normalized', 'nunique'),\n",
    "    first_medication_date=('MedicationDateTime', 'min'),\n",
    "    last_medication_date=('MedicationDateTime', 'max'),\n",
    "    rxout_count=('SourceSystem', lambda x: (x == 'RxOut').sum()),\n",
    "    bcma_count=('SourceSystem', lambda x: (x == 'BCMA').sum())\n",
    ").reset_index()\n",
    "\n",
    "# Calculate medication timespan\n",
    "patient_features['medication_timespan_days'] = (\n",
    "    patient_features['last_medication_date'] - patient_features['first_medication_date']\n",
    ").dt.days\n",
    "\n",
    "# Calculate average medications per day (medication burden)\n",
    "patient_features['avg_medications_per_day'] = (\n",
    "    patient_features['medication_count'] / \n",
    "    (patient_features['medication_timespan_days'] + 1)  # +1 to avoid division by zero\n",
    ")\n",
    "\n",
    "# Calculate source system diversity (0 = single source, higher = more diverse)\n",
    "patient_features['source_diversity'] = (\n",
    "    (patient_features['rxout_count'] > 0).astype(int) + \n",
    "    (patient_features['bcma_count'] > 0).astype(int)\n",
    ")\n",
    "\n",
    "logging.info(f\"Created medication profile features for {len(patient_features)} patients\")\n",
    "\n",
    "print(\"\\nPatient Medication Profile Features:\")\n",
    "patient_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-medication-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate medication diversity using Shannon entropy\n",
    "\n",
    "logging.info(\"Calculating medication diversity scores...\")\n",
    "\n",
    "def calculate_medication_diversity(patient_meds):\n",
    "    \"\"\"Calculate Shannon entropy of medication distribution for a patient.\"\"\"\n",
    "    med_counts = patient_meds['DrugName_Normalized'].value_counts()\n",
    "    if len(med_counts) <= 1:\n",
    "        return 0.0\n",
    "    return entropy(med_counts, base=2)\n",
    "\n",
    "diversity_scores = df_meds.groupby('PatientSID').apply(calculate_medication_diversity)\n",
    "diversity_scores = diversity_scores.reset_index(name='medication_diversity')\n",
    "\n",
    "# Merge with patient features\n",
    "patient_features = patient_features.merge(diversity_scores, on='PatientSID', how='left')\n",
    "\n",
    "logging.info(\"Medication diversity scores added\")\n",
    "\n",
    "print(\"\\nMedication diversity distribution:\")\n",
    "print(patient_features['medication_diversity'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify-patient-ddis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all DDI pairs for each patient\n",
    "\n",
    "logging.info(\"Identifying DDI pairs for each patient...\")\n",
    "\n",
    "def find_patient_ddi_pairs(patient_id, patient_meds_df, ddi_df):\n",
    "    \"\"\"\n",
    "    Find all DDI pairs for a given patient.\n",
    "    Returns list of dicts with interaction details.\n",
    "    \"\"\"\n",
    "    # Get patient's unique medications\n",
    "    meds = patient_meds_df[patient_meds_df['PatientSID'] == patient_id]['DrugName_Normalized'].dropna().unique()\n",
    "    \n",
    "    interactions = []\n",
    "    \n",
    "    # Check all pairs of patient's medications\n",
    "    for drug1, drug2 in combinations(meds, 2):\n",
    "        # Check if this pair exists in DDI dataset (either order)\n",
    "        match = ddi_df[\n",
    "            ((ddi_df['Drug1_Normalized'] == drug1) & (ddi_df['Drug2_Normalized'] == drug2)) |\n",
    "            ((ddi_df['Drug1_Normalized'] == drug2) & (ddi_df['Drug2_Normalized'] == drug1))\n",
    "        ]\n",
    "        \n",
    "        if not match.empty:\n",
    "            for _, row in match.iterrows():\n",
    "                interactions.append({\n",
    "                    'PatientSID': patient_id,\n",
    "                    'Drug1': drug1,\n",
    "                    'Drug2': drug2,\n",
    "                    'Severity': row['Severity'],\n",
    "                    'Interaction': row['Interaction Description']\n",
    "                })\n",
    "    \n",
    "    return interactions\n",
    "\n",
    "# Find DDI pairs for all patients\n",
    "all_patient_ddis = []\n",
    "for patient_id in df_meds['PatientSID'].unique():\n",
    "    patient_ddis = find_patient_ddi_pairs(patient_id, df_meds, df_ddi)\n",
    "    all_patient_ddis.extend(patient_ddis)\n",
    "\n",
    "# Create DataFrame of patient DDI pairs\n",
    "df_patient_ddis = pd.DataFrame(all_patient_ddis)\n",
    "\n",
    "logging.info(f\"Found {len(df_patient_ddis)} total DDI pairs across all patients\")\n",
    "\n",
    "if len(df_patient_ddis) > 0:\n",
    "    print(f\"\\nDDI pairs found: {len(df_patient_ddis)}\")\n",
    "    print(f\"Patients with DDIs: {df_patient_ddis['PatientSID'].nunique()}\")\n",
    "    print(\"\\nSeverity distribution:\")\n",
    "    print(df_patient_ddis['Severity'].value_counts())\n",
    "    print(\"\\nSample DDI pairs:\")\n",
    "    print(df_patient_ddis.head())\n",
    "else:\n",
    "    print(\"\\n⚠ No DDI pairs found in current patient data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-ddi-risk-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DDI risk features per patient\n",
    "\n",
    "logging.info(\"Calculating patient DDI risk features...\")\n",
    "\n",
    "if len(df_patient_ddis) > 0:\n",
    "    # Count DDI pairs by severity for each patient\n",
    "    ddi_counts = df_patient_ddis.groupby(['PatientSID', 'Severity']).size().unstack(fill_value=0)\n",
    "    ddi_counts = ddi_counts.add_prefix('ddi_severity_').reset_index()\n",
    "    \n",
    "    # Total DDI pair count\n",
    "    ddi_total = df_patient_ddis.groupby('PatientSID').size().reset_index(name='ddi_pair_count')\n",
    "    \n",
    "    # Merge DDI features\n",
    "    ddi_features = ddi_total.merge(ddi_counts, on='PatientSID', how='left')\n",
    "    \n",
    "    # Calculate weighted DDI risk score (High=3, Moderate=2, Low=1)\n",
    "    severity_weights = {'High': 3, 'Moderate': 2, 'Low': 1}\n",
    "    ddi_features['total_ddi_risk_score'] = 0\n",
    "    for severity, weight in severity_weights.items():\n",
    "        col_name = f'ddi_severity_{severity}'\n",
    "        if col_name in ddi_features.columns:\n",
    "            ddi_features['total_ddi_risk_score'] += ddi_features[col_name] * weight\n",
    "    \n",
    "    # Maximum severity level (3=High, 2=Moderate, 1=Low, 0=None)\n",
    "    def get_max_severity(row):\n",
    "        if 'ddi_severity_High' in row and row.get('ddi_severity_High', 0) > 0:\n",
    "            return 3\n",
    "        elif 'ddi_severity_Moderate' in row and row.get('ddi_severity_Moderate', 0) > 0:\n",
    "            return 2\n",
    "        elif 'ddi_severity_Low' in row and row.get('ddi_severity_Low', 0) > 0:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    ddi_features['max_severity_level'] = ddi_features.apply(get_max_severity, axis=1)\n",
    "    \n",
    "    # Merge with patient features\n",
    "    patient_features = patient_features.merge(ddi_features, on='PatientSID', how='left')\n",
    "    \n",
    "    logging.info(f\"Added DDI risk features for {len(ddi_features)} patients with DDIs\")\n",
    "else:\n",
    "    # Add empty DDI columns if no DDIs found\n",
    "    patient_features['ddi_pair_count'] = 0\n",
    "    patient_features['total_ddi_risk_score'] = 0\n",
    "    patient_features['max_severity_level'] = 0\n",
    "    logging.warning(\"No DDI pairs found - added zero-value DDI risk features\")\n",
    "\n",
    "# Fill NaN values with 0 for patients without DDIs\n",
    "ddi_cols = [col for col in patient_features.columns if 'ddi' in col.lower()]\n",
    "patient_features[ddi_cols] = patient_features[ddi_cols].fillna(0)\n",
    "\n",
    "print(\"\\nPatient DDI Risk Features:\")\n",
    "print(patient_features[['PatientSID', 'unique_medications', 'ddi_pair_count', \n",
    "                         'total_ddi_risk_score', 'max_severity_level']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-ddi-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DDI density (proportion of possible pairs that are DDIs)\n",
    "\n",
    "logging.info(\"Calculating DDI density scores...\")\n",
    "\n",
    "def calculate_ddi_density(row):\n",
    "    \"\"\"Calculate DDI density: actual DDI pairs / total possible pairs.\"\"\"\n",
    "    n_meds = row['unique_medications']\n",
    "    if n_meds < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Total possible pairs: n choose 2 = n*(n-1)/2\n",
    "    total_possible_pairs = (n_meds * (n_meds - 1)) / 2\n",
    "    \n",
    "    ddi_pairs = row['ddi_pair_count']\n",
    "    \n",
    "    return ddi_pairs / total_possible_pairs if total_possible_pairs > 0 else 0.0\n",
    "\n",
    "patient_features['ddi_density'] = patient_features.apply(calculate_ddi_density, axis=1)\n",
    "\n",
    "logging.info(\"DDI density scores calculated\")\n",
    "\n",
    "print(\"\\nDDI density distribution:\")\n",
    "print(patient_features['ddi_density'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-polypharmacy-flag",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polypharmacy indicator (commonly defined as 5+ medications)\n",
    "\n",
    "logging.info(\"Adding polypharmacy indicators...\")\n",
    "\n",
    "patient_features['is_polypharmacy'] = (patient_features['unique_medications'] >= 5).astype(int)\n",
    "patient_features['is_high_ddi_risk'] = (patient_features['max_severity_level'] >= 2).astype(int)  # Moderate or High\n",
    "\n",
    "polypharmacy_count = patient_features['is_polypharmacy'].sum()\n",
    "high_risk_count = patient_features['is_high_ddi_risk'].sum()\n",
    "\n",
    "logging.info(f\"Polypharmacy patients: {polypharmacy_count}\")\n",
    "logging.info(f\"High DDI risk patients: {high_risk_count}\")\n",
    "\n",
    "print(f\"\\nPolypharmacy patients (5+ medications): {polypharmacy_count} / {len(patient_features)}\")\n",
    "print(f\"High DDI risk patients (moderate/high severity): {high_risk_count} / {len(patient_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bln6g1lq3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographics into patient features\n",
    "\n",
    "logging.info(\"Merging demographics into patient features...\")\n",
    "\n",
    "# Select demographics columns to merge\n",
    "demo_cols = ['PatientSID', 'Age', 'AgeGroup', 'IsElderly', 'Gender']\n",
    "df_demo_subset = df_demo[demo_cols]\n",
    "\n",
    "# Merge demographics\n",
    "patient_features = patient_features.merge(df_demo_subset, on='PatientSID', how='left')\n",
    "\n",
    "# Check for patients without demographics\n",
    "missing_demo = patient_features['Age'].isnull().sum()\n",
    "if missing_demo > 0:\n",
    "    logging.warning(f\"{missing_demo} patients without demographics data\")\n",
    "else:\n",
    "    logging.info(\"All patients have demographics data\")\n",
    "\n",
    "logging.info(\"Demographics merged successfully\")\n",
    "\n",
    "print(f\"\\nPatient features now include demographics:\")\n",
    "print(f\"Shape: {patient_features.shape}\")\n",
    "print(\"\\nDemographics columns added: Age, AgeGroup, IsElderly, Gender\")\n",
    "print(\"\\nSample data:\")\n",
    "print(patient_features[['PatientSID', 'Age', 'Gender', 'IsElderly', 'unique_medications', 'ddi_pair_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dusx21rjpk",
   "metadata": {},
   "source": [
    "### Join Demographics into Patient Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-features-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient-level features summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PATIENT-LEVEL FEATURES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal patients: {len(patient_features)}\")\n",
    "print(f\"Total features: {len(patient_features.columns)}\")\n",
    "\n",
    "print(\"\\nFeature groups:\")\n",
    "print(\"  - Medication profile: medication_count, unique_medications, medication_diversity\")\n",
    "print(\"  - Temporal: first/last_medication_date, medication_timespan_days, avg_medications_per_day\")\n",
    "print(\"  - Source system: rxout_count, bcma_count, source_diversity\")\n",
    "print(\"  - DDI risk: ddi_pair_count, severity counts, total_ddi_risk_score, max_severity_level\")\n",
    "print(\"  - DDI metrics: ddi_density\")\n",
    "print(\"  - Indicators: is_polypharmacy, is_high_ddi_risk\")\n",
    "\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(patient_features[['unique_medications', 'ddi_pair_count', 'total_ddi_risk_score', \n",
    "                         'ddi_density', 'medication_diversity']].describe())\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "patient_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: DDI Pair-Level Features\n",
    "\n",
    "Create detailed features for each patient-specific DDI pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddi-pair-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DDI pair-level feature dataset\n",
    "\n",
    "logging.info(\"Creating DDI pair-level features...\")\n",
    "\n",
    "if len(df_patient_ddis) > 0:\n",
    "    # Start with patient DDI pairs\n",
    "    df_ddi_pairs = df_patient_ddis.copy()\n",
    "    \n",
    "    # Add patient context features\n",
    "    patient_context = patient_features[['PatientSID', 'unique_medications', 'medication_count', \n",
    "                                         'total_ddi_risk_score', 'is_polypharmacy']]\n",
    "    df_ddi_pairs = df_ddi_pairs.merge(patient_context, on='PatientSID', how='left')\n",
    "    \n",
    "    # Rename for clarity\n",
    "    df_ddi_pairs = df_ddi_pairs.rename(columns={\n",
    "        'unique_medications': 'patient_medication_count',\n",
    "        'medication_count': 'patient_total_records',\n",
    "        'total_ddi_risk_score': 'patient_total_risk_score',\n",
    "        'is_polypharmacy': 'patient_is_polypharmacy'\n",
    "    })\n",
    "    \n",
    "    logging.info(f\"Created DDI pair features for {len(df_ddi_pairs)} interactions\")\n",
    "    \n",
    "    print(f\"\\nDDI Pair Features Shape: {df_ddi_pairs.shape}\")\n",
    "    print(\"\\nSample DDI pair features:\")\n",
    "    print(df_ddi_pairs.head())\n",
    "else:\n",
    "    df_ddi_pairs = pd.DataFrame()  # Empty dataframe\n",
    "    logging.warning(\"No DDI pairs found - creating empty DDI pair features dataset\")\n",
    "    print(\"\\n⚠ No DDI pairs to create features for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddi-temporal-overlap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal overlap for DDI pairs\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    logging.info(\"Calculating temporal overlap for DDI pairs...\")\n",
    "    \n",
    "    def calculate_temporal_overlap(row, meds_df):\n",
    "        \"\"\"Calculate temporal overlap between two drugs for a patient.\"\"\"\n",
    "        patient_id = row['PatientSID']\n",
    "        drug1 = row['Drug1']\n",
    "        drug2 = row['Drug2']\n",
    "        \n",
    "        # Get medication records for each drug\n",
    "        drug1_records = meds_df[\n",
    "            (meds_df['PatientSID'] == patient_id) & \n",
    "            (meds_df['DrugName_Normalized'] == drug1)\n",
    "        ]\n",
    "        drug2_records = meds_df[\n",
    "            (meds_df['PatientSID'] == patient_id) & \n",
    "            (meds_df['DrugName_Normalized'] == drug2)\n",
    "        ]\n",
    "        \n",
    "        if len(drug1_records) == 0 or len(drug2_records) == 0:\n",
    "            return pd.Series({\n",
    "                'temporal_overlap': 0,\n",
    "                'first_occurrence_date': None,\n",
    "                'drug1_first_date': None,\n",
    "                'drug2_first_date': None\n",
    "            })\n",
    "        \n",
    "        # Get date ranges\n",
    "        drug1_first = drug1_records['MedicationDateTime'].min()\n",
    "        drug1_last = drug1_records['MedicationDateTime'].max()\n",
    "        drug2_first = drug2_records['MedicationDateTime'].min()\n",
    "        drug2_last = drug2_records['MedicationDateTime'].max()\n",
    "        \n",
    "        # Calculate overlap\n",
    "        overlap_start = max(drug1_first, drug2_first)\n",
    "        overlap_end = min(drug1_last, drug2_last)\n",
    "        \n",
    "        has_overlap = 1 if overlap_start <= overlap_end else 0\n",
    "        \n",
    "        # First occurrence is when both drugs are active\n",
    "        first_occurrence = overlap_start if has_overlap else max(drug1_first, drug2_first)\n",
    "        \n",
    "        return pd.Series({\n",
    "            'temporal_overlap': has_overlap,\n",
    "            'first_occurrence_date': first_occurrence,\n",
    "            'drug1_first_date': drug1_first,\n",
    "            'drug2_first_date': drug2_first\n",
    "        })\n",
    "    \n",
    "    # Apply temporal overlap calculation\n",
    "    temporal_features = df_ddi_pairs.apply(lambda row: calculate_temporal_overlap(row, df_meds), axis=1)\n",
    "    df_ddi_pairs = pd.concat([df_ddi_pairs, temporal_features], axis=1)\n",
    "    \n",
    "    # Calculate days between drug starts\n",
    "    df_ddi_pairs['days_between_drug_starts'] = (\n",
    "        df_ddi_pairs['drug2_first_date'] - df_ddi_pairs['drug1_first_date']\n",
    "    ).dt.days.abs()\n",
    "    \n",
    "    overlap_count = df_ddi_pairs['temporal_overlap'].sum()\n",
    "    logging.info(f\"DDI pairs with temporal overlap: {overlap_count} / {len(df_ddi_pairs)}\")\n",
    "    \n",
    "    print(f\"\\nTemporal overlap: {overlap_count} / {len(df_ddi_pairs)} DDI pairs have concurrent use\")\n",
    "    print(\"\\nDays between drug starts:\")\n",
    "    print(df_ddi_pairs['days_between_drug_starts'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddi-interaction-type",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interaction type from description\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    logging.info(\"Extracting interaction types...\")\n",
    "    \n",
    "    def extract_interaction_type(description):\n",
    "        \"\"\"Extract primary interaction mechanism from description.\"\"\"\n",
    "        if pd.isna(description):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        desc_lower = description.lower()\n",
    "        \n",
    "        # Check for common interaction types\n",
    "        if 'bleeding' in desc_lower or 'anticoagulant' in desc_lower:\n",
    "            return 'Bleeding Risk'\n",
    "        elif 'hyperkalemia' in desc_lower or 'potassium' in desc_lower:\n",
    "            return 'Hyperkalemia'\n",
    "        elif 'serotonin' in desc_lower:\n",
    "            return 'Serotonin Syndrome'\n",
    "        elif 'nephrotoxic' in desc_lower or 'kidney' in desc_lower:\n",
    "            return 'Nephrotoxicity'\n",
    "        elif 'hepatotoxic' in desc_lower or 'liver' in desc_lower:\n",
    "            return 'Hepatotoxicity'\n",
    "        elif 'qtc' in desc_lower or 'qt prolong' in desc_lower:\n",
    "            return 'QT Prolongation'\n",
    "        elif 'serum concentration' in desc_lower:\n",
    "            return 'Altered Drug Levels'\n",
    "        elif 'adverse effect' in desc_lower:\n",
    "            return 'Additive Adverse Effects'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    df_ddi_pairs['interaction_type'] = df_ddi_pairs['Interaction'].apply(extract_interaction_type)\n",
    "    \n",
    "    logging.info(\"Interaction types extracted\")\n",
    "    \n",
    "    print(\"\\nInteraction type distribution:\")\n",
    "    print(df_ddi_pairs['interaction_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddi-pairs-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDI pair-level features summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DDI PAIR-LEVEL FEATURES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    print(f\"\\nTotal DDI pairs: {len(df_ddi_pairs)}\")\n",
    "    print(f\"Total features: {len(df_ddi_pairs.columns)}\")\n",
    "    print(f\"Patients with DDIs: {df_ddi_pairs['PatientSID'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nFeature groups:\")\n",
    "    print(\"  - Identification: PatientSID, Drug1, Drug2\")\n",
    "    print(\"  - Interaction: Severity, interaction_type, Interaction (description)\")\n",
    "    print(\"  - Temporal: temporal_overlap, first_occurrence_date, days_between_drug_starts\")\n",
    "    print(\"  - Patient context: patient_medication_count, patient_total_risk_score, patient_is_polypharmacy\")\n",
    "    \n",
    "    print(\"\\nSeverity distribution:\")\n",
    "    print(df_ddi_pairs['Severity'].value_counts())\n",
    "    \n",
    "    print(\"\\nColumns:\")\n",
    "    print(list(df_ddi_pairs.columns))\n",
    "else:\n",
    "    print(\"\\n⚠ No DDI pairs in dataset\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Feature Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-features-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate patient-level features\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PATIENT-LEVEL FEATURES VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "missing = patient_features.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"None\")\n",
    "\n",
    "# Check for infinite values\n",
    "numeric_cols = patient_features.select_dtypes(include=[np.number]).columns\n",
    "inf_check = patient_features[numeric_cols].isin([np.inf, -np.inf]).sum()\n",
    "print(\"\\nInfinite values:\")\n",
    "print(inf_check[inf_check > 0] if inf_check.sum() > 0 else \"None\")\n",
    "\n",
    "# Check for negative values where they shouldn't be\n",
    "count_cols = [col for col in patient_features.columns if 'count' in col.lower()]\n",
    "negative_counts = (patient_features[count_cols] < 0).sum()\n",
    "print(\"\\nNegative count values:\")\n",
    "print(negative_counts[negative_counts > 0] if negative_counts.sum() > 0 else \"None\")\n",
    "\n",
    "# Distribution summary\n",
    "print(\"\\nKey feature distributions:\")\n",
    "print(patient_features[['unique_medications', 'ddi_pair_count', 'total_ddi_risk_score']].describe())\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddi-pairs-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate DDI pair-level features\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"DDI PAIR-LEVEL FEATURES VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values:\")\n",
    "    missing = df_ddi_pairs.isnull().sum()\n",
    "    print(missing[missing > 0] if missing.sum() > 0 else \"None\")\n",
    "    \n",
    "    # Check severity values are valid\n",
    "    valid_severities = ['High', 'Moderate', 'Low', 'Unknown']\n",
    "    invalid_severity = ~df_ddi_pairs['Severity'].isin(valid_severities)\n",
    "    print(f\"\\nInvalid severity values: {invalid_severity.sum()}\")\n",
    "    \n",
    "    # Check temporal overlap consistency\n",
    "    print(f\"\\nTemporal overlap: {df_ddi_pairs['temporal_overlap'].sum()} / {len(df_ddi_pairs)} pairs\")\n",
    "    \n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-correlations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations between key patient features\n",
    "\n",
    "print(\"\\nCorrelation analysis (patient-level features):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "corr_features = ['unique_medications', 'ddi_pair_count', 'total_ddi_risk_score', \n",
    "                 'ddi_density', 'medication_diversity']\n",
    "corr_matrix = patient_features[corr_features].corr()\n",
    "\n",
    "print(corr_matrix)\n",
    "print(\"\\nNote: High correlation (>0.8) between features may indicate redundancy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Write Features to v3_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-patient-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write patient-level features to v3_features\n",
    "\n",
    "patient_features_filename = \"patients_features.parquet\"\n",
    "patient_features_uri = f\"s3://{DEST_BUCKET}/{V3_FEATURES_DDI_PREFIX}{patient_features_filename}\"\n",
    "logging.info(f\"Writing patient features: {patient_features_uri}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "patient_features.to_parquet(\n",
    "    patient_features_uri,\n",
    "    engine='pyarrow',\n",
    "    filesystem=fs,\n",
    "    compression='snappy',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "logging.info(f\"Successfully wrote {len(patient_features):,} patient records in {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"✓ Patient features written to: {patient_features_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-ddi-pairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DDI pair-level features to v3_features\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    ddi_pairs_filename = \"ddi_pairs_features.parquet\"\n",
    "    ddi_pairs_uri = f\"s3://{DEST_BUCKET}/{V3_FEATURES_DDI_PREFIX}{ddi_pairs_filename}\"\n",
    "    logging.info(f\"Writing DDI pair features: {ddi_pairs_uri}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_ddi_pairs.to_parquet(\n",
    "        ddi_pairs_uri,\n",
    "        engine='pyarrow',\n",
    "        filesystem=fs,\n",
    "        compression='snappy',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    logging.info(f\"Successfully wrote {len(df_ddi_pairs):,} DDI pair records in {elapsed:.2f}s\")\n",
    "    \n",
    "    print(f\"✓ DDI pair features written to: {ddi_pairs_uri}\")\n",
    "else:\n",
    "    logging.warning(\"No DDI pairs to write\")\n",
    "    print(\"⚠ No DDI pair features to write (no interactions found)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Verification and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify patient features by reading back\n",
    "\n",
    "logging.info(\"Verifying patient features...\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_patient_verify = pd.read_parquet(patient_features_uri, filesystem=fs)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "assert len(df_patient_verify) == len(patient_features), \"Row count mismatch!\"\n",
    "assert len(df_patient_verify.columns) == len(patient_features.columns), \"Column count mismatch!\"\n",
    "\n",
    "logging.info(f\"✓ Patient features verification successful: {len(df_patient_verify):,} rows in {elapsed:.2f}s\")\n",
    "\n",
    "print(\"\\nPatient Features (first 3 rows):\")\n",
    "print(df_patient_verify.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final feature engineering summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nPATIENT-LEVEL FEATURES:\")\n",
    "print(f\"  Output: s3://{DEST_BUCKET}/{V3_FEATURES_DDI_PREFIX}{patient_features_filename}\")\n",
    "print(f\"  Patients: {len(patient_features):,}\")\n",
    "print(f\"  Features: {len(patient_features.columns)}\")\n",
    "print(f\"  Polypharmacy patients: {patient_features['is_polypharmacy'].sum()}\")\n",
    "print(f\"  High DDI risk patients: {patient_features['is_high_ddi_risk'].sum()}\")\n",
    "print(f\"  Status: ✓ Complete\")\n",
    "\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    print(\"\\nDDI PAIR-LEVEL FEATURES:\")\n",
    "    print(f\"  Output: s3://{DEST_BUCKET}/{V3_FEATURES_DDI_PREFIX}{ddi_pairs_filename}\")\n",
    "    print(f\"  DDI pairs: {len(df_ddi_pairs):,}\")\n",
    "    print(f\"  Features: {len(df_ddi_pairs.columns)}\")\n",
    "    print(f\"  Patients affected: {df_ddi_pairs['PatientSID'].nunique()}\")\n",
    "    print(f\"  Temporal overlap: {df_ddi_pairs['temporal_overlap'].sum()} pairs\")\n",
    "    print(f\"  Status: ✓ Complete\")\n",
    "else:\n",
    "    print(\"\\nDDI PAIR-LEVEL FEATURES:\")\n",
    "    print(f\"  Status: ⚠ No DDI pairs found (skipped)\")\n",
    "\n",
    "print(\"\\nFEATURE CATEGORIES:\")\n",
    "print(\"  ✓ Medication profile (count, diversity, burden)\")\n",
    "print(\"  ✓ Temporal patterns (timespan, frequency)\")\n",
    "print(\"  ✓ Source system (RxOut, BCMA, diversity)\")\n",
    "print(\"  ✓ DDI risk (pair count, severity, risk score, density)\")\n",
    "print(\"  ✓ Clinical indicators (polypharmacy, high risk flags)\")\n",
    "if len(df_ddi_pairs) > 0:\n",
    "    print(\"  ✓ Interaction details (type, temporal overlap)\")\n",
    "\n",
    "print(\"\\nUSE CASES SUPPORTED:\")\n",
    "print(\"  → Patient risk stratification and clustering (05_clustering.ipynb)\")\n",
    "print(\"  → DDI risk scoring and analysis (06_analysis.ipynb)\")\n",
    "print(\"  → Future: Predictive modeling, clinical decision support\")\n",
    "print(\"  → Future: Care coordination analysis (after PhysioNet integration)\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"  → Run 05_clustering.ipynb to identify patient risk groups\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
